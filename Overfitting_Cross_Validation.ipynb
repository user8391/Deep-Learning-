{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM9BlEVpv/L1sGCpfCwnZh/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/user8391/Deep-Learning-/blob/main/Overfitting_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting - Model Learns too much from the training dataset and deduces noise as hidden patterns in the dataset , leading to good performance with training dataset but often terrible performance with testing dataset ."
      ],
      "metadata": {
        "id": "UOQk91mpLpDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methods to avoid Overfitting -\n",
        "1 . CROSS VALIDATION\n",
        "2 . Use REGULARIZATION"
      ],
      "metadata": {
        "id": "P5Z4HpznMVwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Cross Validation manually using numpy"
      ],
      "metadata": {
        "id": "DA2TWg2JWzFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ALL Data = Training set(usually 80%) + Hold out set devset 10%  + Test set 10%\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "zcojPThzWlnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "iris = sns.load_dataset('iris') # dataframe\n",
        "\n",
        "data = torch.tensor(iris[iris.columns[0:4]].values).float()\n",
        "\n",
        "labels = torch.zeros(data.shape[0], dtype=torch.long)\n",
        "labels[iris.species=='versicolor'] = 1\n",
        "labels[iris.species=='virginica'] = 2"
      ],
      "metadata": {
        "id": "dHRxPosXYrHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperating dataset into train and test (no devset here)\n",
        "'important changes'\n",
        "\n",
        "# how many training examples\n",
        "training_proportion = 0.8\n",
        "training_quantity = int(training_proportion*len(labels) )\n",
        "\n",
        "# creating bool vector to choose from the dataset\n",
        "train_test_bool = np.zeros(len(labels) , dtype = bool)\n",
        "\n",
        "# randomly selecting points from the dataset\n",
        "randomizing_selection = np.random.choice(range(len(labels)),training_quantity , replace = False)\n",
        "train_test_bool[randomizing_selection] = True\n",
        "\n",
        "train_test_bool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXTvEPZ3Zesp",
        "outputId": "71dbfbec-db8d-4ff5-bfc2-a124c4584879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True, False,  True,  True, False,  True, False,\n",
              "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
              "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
              "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
              "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True, False,  True,  True,  True,  True, False,\n",
              "       False,  True, False,  True,  True, False,  True,  True, False,\n",
              "        True,  True, False,  True,  True,  True,  True,  True,  True,\n",
              "       False,  True, False,  True,  True,  True,  True,  True, False,\n",
              "       False,  True,  True, False,  True,  True,  True,  True, False,\n",
              "        True, False,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(4,12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12,12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12,3)\n",
        ")\n",
        "\n",
        "epochs = 1000\n",
        "losses = np.zeros(epochs)\n",
        "current_acc = []\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters() , lr = 0.01)\n",
        "\n",
        "for epochi in range(epochs):\n",
        "\n",
        "    'important changes'\n",
        "    # forward\n",
        "    yHat = model(data[train_test_bool , :]) # only trains on the instances where the value of train_test_bool is True\n",
        "\n",
        "    current_acc.append(100*torch.mean((torch.argmax(yHat , axis = 1) == labels[train_test_bool]).float()))\n",
        "\n",
        "    # losses\n",
        "    loss = loss_fn(yHat , labels[train_test_bool])\n",
        "    losses[epochi] = loss\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# final training data forward pass\n",
        "yHat = model(data[train_test_bool , :]) # for training data\n",
        "trainingacc = 100*torch.mean((torch.argmax(yHat , axis = 1) == labels[train_test_bool]).float())\n",
        "\n",
        "# final test accuracy\n",
        "yHat = model(data[~train_test_bool , :])  # ~ for testing data as '~' negates the Trues\n",
        "testingacc = 100*torch.mean((torch.argmax(yHat , axis = 1) == labels[~train_test_bool]).float())\n",
        "\n",
        "print(f'training acc: {trainingacc}')\n",
        "print(f'testing acc: {testingacc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAxCj_Adcwi3",
        "outputId": "fae77ac2-fb9d-4a30-af0e-9c50eecdc35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training acc: 99.16666412353516\n",
            "testing acc: 96.66666412353516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross validation with scikitlearn\n"
      ],
      "metadata": {
        "id": "XmGz6Kxh_c4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# New\n",
        "from sklearn.model_selection import train_test_split # function is used for splitting the data into training set and testing set"
      ],
      "metadata": {
        "id": "ywUSuvco_cRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "iris = sns.load_dataset('iris')\n",
        "data = torch.tensor(iris[iris.columns[0:4]].values).float()\n",
        "\n",
        "labels = torch.zeros(data.shape[0] , dtype=torch.long)\n",
        "labels[iris.species == 'versicolor'] = 1\n",
        "labels[iris.species == 'virginica'] = 2\n",
        "\n",
        "# the given function splits the data and their labels into training data , labels and testing data , labels\n",
        "# makes it very easy as compared to building logically from ground up\n",
        "\n",
        "training_data , testing_data , training_labels , testing_labels = train_test_split(data , labels , test_size=0.2)\n",
        "# test_size tells the function about the size of the proportion\n",
        "# or use train size\n",
        "# train_size tells the function about the size of the proportion\n",
        "\n",
        "# It also Randomizes the training and the testing data by default without changing the order of features | to disable type shuffle = False\n",
        "\n",
        "print(training_data.shape)\n",
        "print(testing_data.shape)\n",
        "print(training_labels)\n",
        "print(testing_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NkI8gaNAXoa",
        "outputId": "b6777933-77a4-4b0c-d4bc-9c5bde71033b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([120, 4])\n",
            "torch.Size([30, 4])\n",
            "tensor([0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 1, 2, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1, 2, 1,\n",
            "        1, 1, 2, 0, 0, 0, 2, 0, 2, 1, 0, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 2, 1, 0,\n",
            "        1, 0, 2, 2, 2, 0, 2, 1, 2, 0, 0, 1, 2, 0, 2, 0, 2, 1, 2, 1, 1, 1, 2, 0,\n",
            "        1, 1, 0, 1, 2, 2, 0, 2, 0, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 0, 1, 1, 0, 0,\n",
            "        1, 1, 2, 0, 2, 1, 1, 2, 0, 1, 0, 1, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 1, 1])\n",
            "tensor([0, 2, 0, 0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0,\n",
            "        1, 0, 0, 0, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(4,12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12,12),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(12,3)\n",
        ")\n",
        "\n",
        "epochs = 1000\n",
        "losses = np.zeros(epochs)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters() , lr = 0.01)\n",
        "\n",
        "for epochi in range(epochs):\n",
        "\n",
        "\n",
        "    # forward\n",
        "    yHat = model(training_data) # only trains on the instances where the value of train_test_bool is True\n",
        "\n",
        "\n",
        "\n",
        "    # losses\n",
        "    loss = loss_fn(yHat , training_labels)\n",
        "    losses[epochi] = loss\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# final training data forward pass\n",
        "yHat = model(training_data) # for training data\n",
        "trainingacc = 100*torch.mean((torch.argmax(yHat , axis = 1) == training_labels).float())\n",
        "\n",
        "# final test accuracy\n",
        "outputs = model(testing_data)\n",
        "testingacc = 100*torch.mean((torch.argmax(outputs , axis = 1) == testing_labels).float())\n",
        "\n",
        "print(f'training acc: {trainingacc}')\n",
        "print(f'testing acc: {testingacc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xTuTfxBFuOS",
        "outputId": "a5368fca-6e4b-4209-f36c-e8022b785b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4009412988.py:24: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  losses[epochi] = loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training acc: 98.33333587646484\n",
            "testing acc: 93.33333587646484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross validation using Data-Loaders"
      ],
      "metadata": {
        "id": "r47LclyGYw-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# will be used when using with pytorch"
      ],
      "metadata": {
        "id": "OamXYW_lY2kM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}